{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import torch\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pickle\n",
    "from bson.binary import Binary\n",
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "client=MongoClient('133.2.210.24',27017) #ip, port\n",
    "db=client[\"review\"] #database name\n",
    "collection=db[\"test_vector2\"] #collection name\n",
    "#query={} #if you want to use only some data in database, use query to find them\n",
    "cursor=collection.find({},{\"_id\":0,\"id\":1,\"vector\":1,\"label\":1})\n",
    "train_data=np.array([])\n",
    "train_label=np.array([])\n",
    "temp_data=[]\n",
    "for cur in cursor:\n",
    "    dic=cur\n",
    "    temp_data.append(pickle.loads(dic['vector']))\n",
    "    train_label=np.append(train_label,np.array(dic['label']))\n",
    "train_data=np.array(temp_data)\n",
    "\n",
    "n_train = int(len(temp_data)*0.9)\n",
    "for now in range(n_train):\n",
    "    d_train,d_test = np.split(train_data, [n_train])  # 学習データを訓練用とテスト用に分割\n",
    "    l_train,l_test = np.split(train_label, [n_train])  # ラベルデータを訓練用とテスト用に分割\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1536, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "y_train = keras.utils.to_categorical(l_train)\n",
    "y_test = keras.utils.to_categorical(l_test)\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) ### This is where you use the loss function.\n",
    "\n",
    "model.fit(d_train, y_train, epochs=10, batch_size=128)\n",
    "score = model.evaluate(d_test, y_test, batch_size=128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_binary_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=model.predict(np.expand_dims(d_train[0], 0))\n",
    "print(predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
